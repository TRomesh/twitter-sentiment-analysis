{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train deep model + own emmbedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "liwcPath = '../data/LIWIC/LIWC2007_English100131.dic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/pandas_data_frame.csv', index_col=0)\n",
    "all_data = df.where((pd.notnull(df)), '')\n",
    "all_data['hashtag'] = all_data['hashtag'].apply(literal_eval)\n",
    "\n",
    "full_text = all_data['tidy_tweet'][(all_data['label']==1.0) | (all_data['label']==0.0)]\n",
    "y = all_data['label'][(all_data['label']==1.0) | (all_data['label']==0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    when father dysfunct selfish drag kid into dys...\n",
       "1       thank  credit caus they offer wheelchair van  \n",
       "2                                  bihday your majesti\n",
       "3                                  love take with time\n",
       "4                                   factsguid societi \n",
       "5    huge fare talk befor they leav chao disput whe...\n",
       "6                                  camp tomorrow danni\n",
       "7    next school year year exam think about that   ...\n",
       "8                                 love land     cavali\n",
       "9                                          welcom here\n",
       "Name: tidy_tweet, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25569, 64) (25569,)\n",
      "(6393, 64) (6393,)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from personal_library.NPL.liwc import LIWCProcessor\n",
    "\n",
    "liwic = LIWCProcessor(liwcPath)\n",
    "liwic_text = liwic.corpus2liwc(full_text)\n",
    "x_train, x_val, y_train, y_val = train_test_split(liwic_text, y, random_state=1992, test_size=0.2)\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,625\n",
      "Trainable params: 2,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 25569 samples, validate on 6393 samples\n",
      "Epoch 1/40\n",
      " - 1s - loss: 0.8198 - acc: 0.5752 - f1: 0.1802 - val_loss: 0.7632 - val_acc: 0.8198 - val_f1: 0.2368\n",
      "Epoch 2/40\n",
      " - 0s - loss: 0.7555 - acc: 0.8366 - f1: 0.2445 - val_loss: 0.7423 - val_acc: 0.8431 - val_f1: 0.2577\n",
      "Epoch 3/40\n",
      " - 0s - loss: 0.7527 - acc: 0.8273 - f1: 0.2473 - val_loss: 0.7464 - val_acc: 0.8620 - val_f1: 0.2536\n",
      "Epoch 4/40\n",
      " - 0s - loss: 0.7392 - acc: 0.8705 - f1: 0.2608 - val_loss: 0.7374 - val_acc: 0.8882 - val_f1: 0.2626\n",
      "Epoch 5/40\n",
      " - 0s - loss: 0.7368 - acc: 0.8684 - f1: 0.2632 - val_loss: 0.7471 - val_acc: 0.8975 - val_f1: 0.2529\n",
      "Epoch 6/40\n",
      " - 0s - loss: 0.7469 - acc: 0.8484 - f1: 0.2531 - val_loss: 0.7430 - val_acc: 0.8214 - val_f1: 0.2570\n",
      "Epoch 7/40\n",
      " - 0s - loss: 0.7410 - acc: 0.8296 - f1: 0.2590 - val_loss: 0.7386 - val_acc: 0.8711 - val_f1: 0.2614\n",
      "Epoch 8/40\n",
      " - 0s - loss: 0.7419 - acc: 0.8328 - f1: 0.2581 - val_loss: 0.7360 - val_acc: 0.8555 - val_f1: 0.2640\n",
      "Epoch 9/40\n",
      " - 0s - loss: 0.7422 - acc: 0.8578 - f1: 0.2578 - val_loss: 0.7453 - val_acc: 0.8154 - val_f1: 0.2547\n",
      "Epoch 10/40\n",
      " - 0s - loss: 0.7365 - acc: 0.8582 - f1: 0.2635 - val_loss: 0.7411 - val_acc: 0.8911 - val_f1: 0.2589\n",
      "Epoch 11/40\n",
      " - 0s - loss: 0.7495 - acc: 0.8323 - f1: 0.2505 - val_loss: 0.7386 - val_acc: 0.8785 - val_f1: 0.2614\n",
      "Epoch 12/40\n",
      " - 0s - loss: 0.7494 - acc: 0.8844 - f1: 0.2506 - val_loss: 0.7266 - val_acc: 0.8688 - val_f1: 0.2734\n",
      "Epoch 13/40\n",
      " - 0s - loss: 0.7387 - acc: 0.8637 - f1: 0.2613 - val_loss: 0.7327 - val_acc: 0.8738 - val_f1: 0.2673\n",
      "Epoch 14/40\n",
      " - 0s - loss: 0.7326 - acc: 0.8664 - f1: 0.2674 - val_loss: 0.7350 - val_acc: 0.8478 - val_f1: 0.2650\n",
      "Epoch 15/40\n",
      " - 0s - loss: 0.7348 - acc: 0.8558 - f1: 0.2652 - val_loss: 0.7412 - val_acc: 0.8681 - val_f1: 0.2588\n",
      "Epoch 16/40\n",
      " - 0s - loss: 0.7339 - acc: 0.8757 - f1: 0.2661 - val_loss: 0.7420 - val_acc: 0.8644 - val_f1: 0.2580\n",
      "Epoch 17/40\n",
      " - 0s - loss: 0.7343 - acc: 0.8792 - f1: 0.2657 - val_loss: 0.7413 - val_acc: 0.8728 - val_f1: 0.2587\n",
      "Epoch 18/40\n",
      " - 0s - loss: 0.7348 - acc: 0.8664 - f1: 0.2652 - val_loss: 0.7368 - val_acc: 0.8417 - val_f1: 0.2632\n",
      "Epoch 19/40\n",
      " - 0s - loss: 0.7276 - acc: 0.8664 - f1: 0.2724 - val_loss: 0.7472 - val_acc: 0.8896 - val_f1: 0.2528\n",
      "Epoch 20/40\n",
      " - 0s - loss: 0.7314 - acc: 0.8723 - f1: 0.2686 - val_loss: 0.7483 - val_acc: 0.8808 - val_f1: 0.2517\n",
      "Epoch 21/40\n",
      " - 0s - loss: 0.7200 - acc: 0.8678 - f1: 0.2800 - val_loss: 0.7456 - val_acc: 0.8705 - val_f1: 0.2544\n",
      "Epoch 22/40\n",
      " - 0s - loss: 0.7269 - acc: 0.8703 - f1: 0.2731 - val_loss: 0.7297 - val_acc: 0.8508 - val_f1: 0.2703\n",
      "Epoch 23/40\n",
      " - 0s - loss: 0.7213 - acc: 0.8599 - f1: 0.2787 - val_loss: 0.7426 - val_acc: 0.8789 - val_f1: 0.2574\n",
      "Epoch 24/40\n",
      " - 0s - loss: 0.7233 - acc: 0.8727 - f1: 0.2767 - val_loss: 0.7495 - val_acc: 0.8328 - val_f1: 0.2505\n",
      "Epoch 25/40\n",
      " - 0s - loss: 0.7191 - acc: 0.8734 - f1: 0.2809 - val_loss: 0.7336 - val_acc: 0.8749 - val_f1: 0.2664\n",
      "Epoch 26/40\n",
      " - 0s - loss: 0.7198 - acc: 0.8682 - f1: 0.2802 - val_loss: 0.7315 - val_acc: 0.8686 - val_f1: 0.2685\n",
      "Epoch 27/40\n",
      " - 0s - loss: 0.7248 - acc: 0.8821 - f1: 0.2752 - val_loss: 0.7483 - val_acc: 0.8810 - val_f1: 0.2517\n",
      "Epoch 28/40\n",
      " - 0s - loss: 0.7275 - acc: 0.8776 - f1: 0.2725 - val_loss: 0.7421 - val_acc: 0.8761 - val_f1: 0.2579\n",
      "Epoch 29/40\n",
      " - 0s - loss: 0.7196 - acc: 0.8685 - f1: 0.2804 - val_loss: 0.7349 - val_acc: 0.8387 - val_f1: 0.2651\n",
      "Epoch 30/40\n",
      " - 0s - loss: 0.7072 - acc: 0.8644 - f1: 0.2928 - val_loss: 0.7340 - val_acc: 0.8817 - val_f1: 0.2660\n",
      "Epoch 31/40\n",
      " - 0s - loss: 0.7333 - acc: 0.8846 - f1: 0.2667 - val_loss: 0.7403 - val_acc: 0.8717 - val_f1: 0.2597\n",
      "Epoch 32/40\n",
      " - 0s - loss: 0.7171 - acc: 0.8725 - f1: 0.2829 - val_loss: 0.7366 - val_acc: 0.8595 - val_f1: 0.2634\n",
      "Epoch 33/40\n",
      " - 0s - loss: 0.7250 - acc: 0.8818 - f1: 0.2750 - val_loss: 0.7303 - val_acc: 0.8520 - val_f1: 0.2697\n",
      "Epoch 34/40\n",
      " - 0s - loss: 0.7195 - acc: 0.8754 - f1: 0.2805 - val_loss: 0.7418 - val_acc: 0.8753 - val_f1: 0.2582\n",
      "Epoch 35/40\n",
      " - 0s - loss: 0.7127 - acc: 0.8709 - f1: 0.2873 - val_loss: 0.7281 - val_acc: 0.8819 - val_f1: 0.2719\n",
      "Epoch 36/40\n",
      " - 0s - loss: 0.7120 - acc: 0.8750 - f1: 0.2880 - val_loss: 0.7330 - val_acc: 0.8735 - val_f1: 0.2670\n",
      "Epoch 37/40\n",
      " - 0s - loss: 0.7147 - acc: 0.8793 - f1: 0.2853 - val_loss: 0.7589 - val_acc: 0.8999 - val_f1: 0.2411\n",
      "Epoch 38/40\n",
      " - 0s - loss: 0.7177 - acc: 0.8678 - f1: 0.2823 - val_loss: 0.7279 - val_acc: 0.8672 - val_f1: 0.2721\n",
      "Epoch 39/40\n",
      " - 0s - loss: 0.7141 - acc: 0.8730 - f1: 0.2859 - val_loss: 0.7291 - val_acc: 0.8617 - val_f1: 0.2709\n",
      "Epoch 40/40\n",
      " - 0s - loss: 0.7114 - acc: 0.8703 - f1: 0.2886 - val_loss: 0.7288 - val_acc: 0.8844 - val_f1: 0.2712\n"
     ]
    }
   ],
   "source": [
    "from personal_library.sce_keras.loss_functions import f1_loss\n",
    "from personal_library.sce_keras.metrics_functions import f1\n",
    "\n",
    "from keras.layers import Dense, LSTM, SpatialDropout1D, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "shape = liwic_text.shape\n",
    "epochs = 40\n",
    "batch_size = 128\n",
    "learnRate = 0.01\n",
    "\n",
    "adam = Adam(lr=learnRate, beta_1=0.9, beta_2=0.999,\n",
    "            epsilon=None, decay=1e-6, amsgrad=False)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.1,  input_shape=(64,)))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=f1_loss,\n",
    "              optimizer=adam,\n",
    "              metrics = ['accuracy', f1])\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=2,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
