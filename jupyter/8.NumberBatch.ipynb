{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Numberbatch or Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiancorrea/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Input,\n",
    "    LSTM,\n",
    "    Embedding,\n",
    "    Dropout,\n",
    "    Activation,\n",
    "    SpatialDropout1D\n",
    ")\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/pandas_data_frame.csv', index_col=0)\n",
    "all_data = df.where((pd.notnull(df)), '')\n",
    "all_data['hashtag'] = all_data['hashtag'].apply(literal_eval)\n",
    "\n",
    "full_text = all_data['tidy_tweet'][(all_data['label']==1.0) | (all_data['label']==0.0)]\n",
    "y = all_data['label'][(all_data['label']==1.0) | (all_data['label']==0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25569, 19) (25569,)\n",
      "(6393, 19) (6393,)\n"
     ]
    }
   ],
   "source": [
    "tk = Tokenizer(lower=True, filters='')\n",
    "tk.fit_on_texts(full_text)\n",
    "\n",
    "train_tokenized = tk.texts_to_sequences(full_text)\n",
    "max_len = 19\n",
    "X = pad_sequences(train_tokenized, maxlen=max_len)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, random_state=1992, test_size=0.2)\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('../model_wehigts/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tk, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # loading\n",
    "# with open('tokenizer.pickle', 'rb') as handle:\n",
    "#     tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_path = '../data/vectors/glove.twitter.27B/glove.twitter.27B.100d.txt'\n",
    "embedding_path = '../data/vectors/numberbatch-17.06.txt'\n",
    "embed_size = 100\n",
    "\n",
    "max_features = 30000\n",
    "\n",
    "def get_coefs(word,*arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tk.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 19)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 19, 100)           1516700   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 19, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,757,701\n",
      "Trainable params: 241,001\n",
      "Non-trainable params: 1,516,700\n",
      "_________________________________________________________________\n",
      "Train on 25569 samples, validate on 6393 samples\n",
      "Epoch 1/200\n",
      "25569/25569 [==============================] - 39s 2ms/step - loss: 0.8716 - acc: 0.0716 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.87493, saving model to ../model_wehigts/6_g_w.hdf5\n",
      "\n",
      "Epoch 00001: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 2/200\n",
      "25569/25569 [==============================] - 39s 2ms/step - loss: 0.8720 - acc: 0.0705 - f1: 0.1280 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.87493 to 0.87493, saving model to ../model_wehigts/6_g_w.hdf5\n",
      "\n",
      "Epoch 00002: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 3/200\n",
      "25569/25569 [==============================] - 37s 1ms/step - loss: 0.8717 - acc: 0.0705 - f1: 0.1283 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.87493 to 0.87493, saving model to ../model_wehigts/6_g_w.hdf5\n",
      "\n",
      "Epoch 00003: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 4/200\n",
      "25569/25569 [==============================] - 37s 1ms/step - loss: 0.8717 - acc: 0.0705 - f1: 0.1283 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.87493 to 0.87493, saving model to ../model_wehigts/6_g_w.hdf5\n",
      "\n",
      "Epoch 00004: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 5/200\n",
      "25569/25569 [==============================] - 37s 1ms/step - loss: 0.8715 - acc: 0.0705 - f1: 0.1285 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00005: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 6/200\n",
      "25569/25569 [==============================] - 37s 1ms/step - loss: 0.8717 - acc: 0.0705 - f1: 0.1283 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00006: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 7/200\n",
      "25569/25569 [==============================] - 37s 1ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00007: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 8/200\n",
      "25569/25569 [==============================] - 37s 1ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00008: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 9/200\n",
      "25569/25569 [==============================] - 37s 1ms/step - loss: 0.8714 - acc: 0.0705 - f1: 0.1286 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00009: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 10/200\n",
      "25569/25569 [==============================] - 37s 1ms/step - loss: 0.8718 - acc: 0.0705 - f1: 0.1282 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00010: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 11/200\n",
      "25569/25569 [==============================] - 37s 1ms/step - loss: 0.8713 - acc: 0.0705 - f1: 0.1287 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00011: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 12/200\n",
      "25569/25569 [==============================] - 37s 1ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00012: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 13/200\n",
      "25569/25569 [==============================] - 38s 1ms/step - loss: 0.8715 - acc: 0.0705 - f1: 0.1285 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00013: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 14/200\n",
      "25569/25569 [==============================] - 37s 1ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00014: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 15/200\n",
      "25569/25569 [==============================] - 37s 1ms/step - loss: 0.8717 - acc: 0.0705 - f1: 0.1283 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00015: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 16/200\n",
      "25569/25569 [==============================] - 37s 1ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00016: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 17/200\n",
      "25569/25569 [==============================] - 37s 1ms/step - loss: 0.8713 - acc: 0.0705 - f1: 0.1287 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00017: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 18/200\n",
      "25569/25569 [==============================] - 38s 1ms/step - loss: 0.8715 - acc: 0.0705 - f1: 0.1285 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00018: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 19/200\n",
      "25569/25569 [==============================] - 38s 1ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00019: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 20/200\n",
      "25569/25569 [==============================] - 38s 1ms/step - loss: 0.8714 - acc: 0.0705 - f1: 0.1286 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00020: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 21/200\n",
      "25569/25569 [==============================] - 38s 1ms/step - loss: 0.8718 - acc: 0.0705 - f1: 0.1282 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00021: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 22/200\n",
      "25569/25569 [==============================] - 38s 1ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00022: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 23/200\n",
      "25569/25569 [==============================] - 38s 1ms/step - loss: 0.8717 - acc: 0.0705 - f1: 0.1283 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00023: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 24/200\n",
      "25569/25569 [==============================] - 38s 1ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00024: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 25/200\n",
      "25569/25569 [==============================] - 41s 2ms/step - loss: 0.8717 - acc: 0.0705 - f1: 0.1283 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00025: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 26/200\n",
      "25569/25569 [==============================] - 43s 2ms/step - loss: 0.8714 - acc: 0.0705 - f1: 0.1286 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00026: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 27/200\n",
      "25569/25569 [==============================] - 43s 2ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00027: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 28/200\n",
      "25569/25569 [==============================] - 43s 2ms/step - loss: 0.8714 - acc: 0.0705 - f1: 0.1286 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00028: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 29/200\n",
      "25569/25569 [==============================] - 44s 2ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00029: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 30/200\n",
      "25569/25569 [==============================] - 44s 2ms/step - loss: 0.8717 - acc: 0.0705 - f1: 0.1283 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00030: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 31/200\n",
      "25569/25569 [==============================] - 44s 2ms/step - loss: 0.8718 - acc: 0.0705 - f1: 0.1282 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00031: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 32/200\n",
      "25569/25569 [==============================] - 44s 2ms/step - loss: 0.8715 - acc: 0.0705 - f1: 0.1285 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00032: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 33/200\n",
      "25569/25569 [==============================] - 45s 2ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00033: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 34/200\n",
      "25569/25569 [==============================] - 45s 2ms/step - loss: 0.8715 - acc: 0.0705 - f1: 0.1285 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00034: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 35/200\n",
      "25569/25569 [==============================] - 45s 2ms/step - loss: 0.8715 - acc: 0.0705 - f1: 0.1285 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00035: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 36/200\n",
      "25569/25569 [==============================] - 45s 2ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00036: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 37/200\n",
      "25569/25569 [==============================] - 45s 2ms/step - loss: 0.8718 - acc: 0.0705 - f1: 0.1282 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00037: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 38/200\n",
      "25569/25569 [==============================] - 45s 2ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00038: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 39/200\n",
      "25569/25569 [==============================] - 45s 2ms/step - loss: 0.8718 - acc: 0.0705 - f1: 0.1282 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00039: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 40/200\n",
      "25569/25569 [==============================] - 46s 2ms/step - loss: 0.8718 - acc: 0.0705 - f1: 0.1282 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00040: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 41/200\n",
      "25569/25569 [==============================] - 46s 2ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00041: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 42/200\n",
      "25569/25569 [==============================] - 46s 2ms/step - loss: 0.8718 - acc: 0.0705 - f1: 0.1282 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00042: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 43/200\n",
      "25569/25569 [==============================] - 46s 2ms/step - loss: 0.8718 - acc: 0.0705 - f1: 0.1282 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00043: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 44/200\n",
      "25569/25569 [==============================] - 46s 2ms/step - loss: 0.8720 - acc: 0.0705 - f1: 0.1280 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00044: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 45/200\n",
      "25569/25569 [==============================] - 46s 2ms/step - loss: 0.8718 - acc: 0.0705 - f1: 0.1282 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00045: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 46/200\n",
      "25569/25569 [==============================] - 47s 2ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00046: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 47/200\n",
      "25569/25569 [==============================] - 48s 2ms/step - loss: 0.8717 - acc: 0.0705 - f1: 0.1283 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00047: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 48/200\n",
      "25569/25569 [==============================] - 48s 2ms/step - loss: 0.8716 - acc: 0.0705 - f1: 0.1284 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00048: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 49/200\n",
      "25569/25569 [==============================] - 48s 2ms/step - loss: 0.8718 - acc: 0.0705 - f1: 0.1282 - val_loss: 0.8749 - val_acc: 0.0688 - val_f1: 0.1251\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.87493\n",
      "\n",
      "Epoch 00049: saving model to ../model_wehigts/6_g_ch.hdf5\n",
      "Epoch 50/200\n",
      "22656/25569 [=========================>....] - ETA: 5s - loss: 0.8703 - acc: 0.0712 - f1: 0.1297"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") \n",
    "from personal_library.sce_keras.loss_functions import f1_loss\n",
    "from personal_library.sce_keras.metrics_functions import f1\n",
    "from personal_library.sce_keras.callbacks import (\n",
    "    LearningRateDecay,\n",
    "    WarmUpCosineDecayScheduler\n",
    ")\n",
    "\n",
    "\n",
    "num_classes = 1\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "learnRate = 0.001\n",
    "lstm_out = 200\n",
    "warmup_epoch = 20\n",
    "\n",
    "lrate_decay = LearningRateDecay(epochs, learnRate).step_decay\n",
    "warm_up_lr = WarmUpCosineDecayScheduler(learning_rate_base=learnRate,\n",
    "                                        warmup_learning_rate=0,\n",
    "                                        warmup_epoch=warmup_epoch,\n",
    "                                        hold_base_rate_steps=5,\n",
    "                                        verbose=0)\n",
    "\n",
    "checkpoint_path = \"../model_wehigts/6_g_w.hdf5\"\n",
    "checkpoint_path1 = \"../model_wehigts/6_g_ch.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                               monitor='val_loss', verbose=2,\n",
    "                               save_best_only=True, mode='min')\n",
    "checkpointer1 = ModelCheckpoint(filepath=checkpoint_path1,\n",
    "                               monitor='val_loss', verbose=2,\n",
    "                               save_best_only=False, mode='min')\n",
    "\n",
    "inp = Input(shape = (max_len,))\n",
    "x = Embedding(nb_words+1, embed_size, weights = [embedding_matrix], trainable=False)(inp)\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "x = LSTM(lstm_out, dropout=0.5, recurrent_dropout=0.5)(x)\n",
    "x = Dense(1, activation = \"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.summary()\n",
    "\n",
    "# 'binary_crossentropy'\n",
    "model.compile(loss=f1_loss, \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy', f1]) \n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[checkpointer, checkpointer1, lrate_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#Load best model\n",
    "model.load_weights(checkpoint_path)\n",
    "y_pred = model.predict(x_val, batch_size=1)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "print(\"Neural Network f1_sklearn: {}\".format(f1_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
