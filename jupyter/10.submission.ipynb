{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "sys.path.append(\"../\") \n",
    "from personal_library.NLP.preprocess import (\n",
    "    remove_pattern,\n",
    "    rm_pun_num_esp_cha,\n",
    "    rm_length_word,\n",
    "    tokenize,\n",
    "    stemmer,\n",
    "    join_tokenize,\n",
    "    hashtag_extract,\n",
    "    count_caps,\n",
    "    hashtag_rm\n",
    ")\n",
    "\n",
    "from personal_library.NLP.data_analysis import(\n",
    "    plot_labels_wordcloud,\n",
    "    plot_hashtag_hist,\n",
    ")\n",
    "\n",
    "from personal_library.NLP.core.model_preprocessors import (\n",
    "    corpus2vec,\n",
    "    standard_word2vec_size\n",
    ")\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to test file\n",
    "test_path = '../data/test_tweets_anuFYb8.csv'\n",
    "test = pd.read_csv(test_path)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['tidy_tweet'] = np.vectorize(remove_pattern)(test['tweet'], \"@[\\w]*\")\n",
    "test['tidy_tweet'] = rm_pun_num_esp_cha(test['tidy_tweet'])\n",
    "test['tidy_tweet'] = rm_length_word(test['tidy_tweet'])\n",
    "tokenized_tweet = tokenize(test['tidy_tweet'])\n",
    "# tokenized_tweet = stemmer(tokenized_tweet)\n",
    "test['tidy_tweet'] = join_tokenize(tokenized_tweet)\n",
    "test['hashtag'] = hashtag_extract(test['tidy_tweet'], flatten=False)\n",
    "test['tidy_tweet'] = np.vectorize(remove_pattern)(test['tidy_tweet'], \"#[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>Name Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>find</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>want everyone   here</td>\n",
       "      <td>[white, supremacists, birds, movie]</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe ways heal your</td>\n",
       "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>cursed child book reservations already where w...</td>\n",
       "      <td>[harrypotter, pottermore, favorite]</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>amazing hilarious  ahmir uncle dave loves misses</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1  31964   @user #white #supremacists want everyone to s...   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  31966  is the hp and the cursed child book up for res...   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0                                              find    \n",
       "1                               want everyone   here   \n",
       "2                            safe ways heal your       \n",
       "3  cursed child book reservations already where w...   \n",
       "4   amazing hilarious  ahmir uncle dave loves misses   \n",
       "\n",
       "                                             hashtag  Name Length  \n",
       "0  [studiolife, aislife, requires, passion, dedic...           11  \n",
       "1                [white, supremacists, birds, movie]           22  \n",
       "2            [acne, altwaystoheal, healthy, healing]           23  \n",
       "3                [harrypotter, pottermore, favorite]           52  \n",
       "4                                   [bihday, nephew]           49  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet = tokenize(test['tidy_tweet'])\n",
    "test.fillna('test', inplace = True)\n",
    "test[\"Name Length\"] = test['tidy_tweet'].str.len()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median:  33.0\n",
      "Media:  37.30923998371809\n",
      "Std:  21.972422741175357\n",
      "MAx:  113\n"
     ]
    }
   ],
   "source": [
    "print(\"Median: \", test[\"Name Length\"].median())\n",
    "print(\"Media: \", test[\"Name Length\"].mean())\n",
    "print(\"Std: \", test[\"Name Length\"].std())\n",
    "print(\"MAx: \", test[\"Name Length\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17197, 19)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# loading\n",
    "with open('../model_wehigts/tokenizer.pickle', 'rb') as handle:\n",
    "    tk = pickle.load(handle)\n",
    "\n",
    "max_len = 120\n",
    "train_tokenized = tk.texts_to_sequences(test['tidy_tweet'])\n",
    "x_test = pad_sequences(train_tokenized, maxlen=max_len)\n",
    "\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
